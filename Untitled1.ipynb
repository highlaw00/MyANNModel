{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AaILaV5Q5Fh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "a431E2JH-2B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/sample_data/Vectorized_Seoul_Datas2019.csv')\n",
        "\n",
        "x = df[['Hour Time', 'Temperature', 'Humidity', 'Weekday', 'Code']].values\n",
        "\n",
        "onehot_code = np.eye(5)[x[:, 4].astype(int)]\n",
        "x = np.hstack((x[:, :4], onehot_code))\n",
        "vectors = df[\"Vector\"].apply(lambda x: [int(i) for i in x.split(\",\")]).tolist()\n",
        "\n",
        "datas = torch.from_numpy(x).float()\n",
        "labels = torch.tensor(vectors).float()\n",
        "print(datas[0])"
      ],
      "metadata": {
        "id": "9Vz_zQ8eBHyK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20a0fdd6-0398-4fe0-d4ad-005e479ca7bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([19.0000, 24.9000, 57.0000,  2.0000,  1.0000,  0.0000,  0.0000,  0.0000,\n",
            "         0.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, x, y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    return self.x[index], self.y[index]\n",
        "\n",
        "dataset = CustomDataset(datas, labels)"
      ],
      "metadata": {
        "id": "SMbIuW-_J6Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.eps = eps\n",
        "        \n",
        "    def forward(self,yhat,y):\n",
        "        loss = torch.sqrt(self.mse(yhat,y) + self.eps)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "8X4ltrf-GQPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "\n",
        "    # 입력은 Hour Time, Temperature, Humidity, Weekday, Code 가 있습니다.\n",
        "    # 각각 숫자, 숫자, 숫자, 숫자, 리스트, 숫자 입니다.\n",
        "\n",
        "    # 출력은 차원이 13인 벡터이며, 각각 회귀 내용을 담고 있습니다.\n",
        "\n",
        "    self.fc1 = nn.Linear(9, 64)\n",
        "    self.fc2 = nn.Linear(64, 128)\n",
        "    self.fc3 = nn.Linear(128, 64)\n",
        "    self.fc4 = nn.Linear(64, 13)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.relu(self.fc1(x))\n",
        "    x = torch.relu(self.fc2(x))\n",
        "    x = torch.relu(self.fc3(x))\n",
        "    output = self.fc4(x)\n",
        "    return output"
      ],
      "metadata": {
        "id": "akuXaXnd6HIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()"
      ],
      "metadata": {
        "id": "-QnrbRGA-Cua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = RMSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "train_dataset = dataset\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "dYSSrq_h-MH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epoch = 100\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "  epoch_loss = 0.0\n",
        "  for inputs, labels in train_dataloader:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    \n",
        "    loss = criterion(outputs, labels)\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epoch, epoch_loss / len(train_dataloader)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R6lvS0aAqD1",
        "outputId": "5220bfe6-700f-401a-a0f0-c9472390b174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 34.2916\n",
            "Epoch [2/100], Loss: 33.2296\n",
            "Epoch [3/100], Loss: 31.8529\n",
            "Epoch [4/100], Loss: 28.4757\n",
            "Epoch [5/100], Loss: 26.2470\n",
            "Epoch [6/100], Loss: 26.0424\n",
            "Epoch [7/100], Loss: 25.9671\n",
            "Epoch [8/100], Loss: 25.9585\n",
            "Epoch [9/100], Loss: 26.0069\n",
            "Epoch [10/100], Loss: 25.7825\n",
            "Epoch [11/100], Loss: 25.8171\n",
            "Epoch [12/100], Loss: 25.7644\n",
            "Epoch [13/100], Loss: 25.7093\n",
            "Epoch [14/100], Loss: 25.6568\n",
            "Epoch [15/100], Loss: 25.6250\n",
            "Epoch [16/100], Loss: 25.4857\n",
            "Epoch [17/100], Loss: 25.3733\n",
            "Epoch [18/100], Loss: 25.2673\n",
            "Epoch [19/100], Loss: 25.2718\n",
            "Epoch [20/100], Loss: 25.2129\n",
            "Epoch [21/100], Loss: 25.0472\n",
            "Epoch [22/100], Loss: 24.9025\n",
            "Epoch [23/100], Loss: 24.7411\n",
            "Epoch [24/100], Loss: 24.4765\n",
            "Epoch [25/100], Loss: 24.4626\n",
            "Epoch [26/100], Loss: 24.1503\n",
            "Epoch [27/100], Loss: 24.0480\n",
            "Epoch [28/100], Loss: 23.8192\n",
            "Epoch [29/100], Loss: 23.6300\n",
            "Epoch [30/100], Loss: 23.3110\n",
            "Epoch [31/100], Loss: 23.1800\n",
            "Epoch [32/100], Loss: 22.9300\n",
            "Epoch [33/100], Loss: 22.7973\n",
            "Epoch [34/100], Loss: 22.5858\n",
            "Epoch [35/100], Loss: 22.5416\n",
            "Epoch [36/100], Loss: 22.4579\n",
            "Epoch [37/100], Loss: 22.4283\n",
            "Epoch [38/100], Loss: 22.2130\n",
            "Epoch [39/100], Loss: 22.2682\n",
            "Epoch [40/100], Loss: 22.2915\n",
            "Epoch [41/100], Loss: 22.2721\n",
            "Epoch [42/100], Loss: 22.2328\n",
            "Epoch [43/100], Loss: 22.2143\n",
            "Epoch [44/100], Loss: 22.2911\n",
            "Epoch [45/100], Loss: 22.2332\n",
            "Epoch [46/100], Loss: 22.1505\n",
            "Epoch [47/100], Loss: 22.0844\n",
            "Epoch [48/100], Loss: 22.2001\n",
            "Epoch [49/100], Loss: 22.2349\n",
            "Epoch [50/100], Loss: 22.1183\n",
            "Epoch [51/100], Loss: 22.2286\n",
            "Epoch [52/100], Loss: 22.2003\n",
            "Epoch [53/100], Loss: 22.0929\n",
            "Epoch [54/100], Loss: 22.1590\n",
            "Epoch [55/100], Loss: 22.0603\n",
            "Epoch [56/100], Loss: 22.2132\n",
            "Epoch [57/100], Loss: 22.2573\n",
            "Epoch [58/100], Loss: 22.1782\n",
            "Epoch [59/100], Loss: 22.0288\n",
            "Epoch [60/100], Loss: 22.1047\n",
            "Epoch [61/100], Loss: 22.2181\n",
            "Epoch [62/100], Loss: 22.1175\n",
            "Epoch [63/100], Loss: 22.0174\n",
            "Epoch [64/100], Loss: 22.0083\n",
            "Epoch [65/100], Loss: 22.2138\n",
            "Epoch [66/100], Loss: 22.1594\n",
            "Epoch [67/100], Loss: 22.1079\n",
            "Epoch [68/100], Loss: 22.0150\n",
            "Epoch [69/100], Loss: 21.9977\n",
            "Epoch [70/100], Loss: 22.0928\n",
            "Epoch [71/100], Loss: 21.9853\n",
            "Epoch [72/100], Loss: 22.0288\n",
            "Epoch [73/100], Loss: 22.0609\n",
            "Epoch [74/100], Loss: 22.0153\n",
            "Epoch [75/100], Loss: 22.0484\n",
            "Epoch [76/100], Loss: 22.0256\n",
            "Epoch [77/100], Loss: 21.9258\n",
            "Epoch [78/100], Loss: 22.0134\n",
            "Epoch [79/100], Loss: 22.0433\n",
            "Epoch [80/100], Loss: 22.0164\n",
            "Epoch [81/100], Loss: 22.0490\n",
            "Epoch [82/100], Loss: 22.1125\n",
            "Epoch [83/100], Loss: 22.0896\n",
            "Epoch [84/100], Loss: 21.9608\n",
            "Epoch [85/100], Loss: 21.9435\n",
            "Epoch [86/100], Loss: 22.0014\n",
            "Epoch [87/100], Loss: 22.0474\n",
            "Epoch [88/100], Loss: 22.0674\n",
            "Epoch [89/100], Loss: 21.9498\n",
            "Epoch [90/100], Loss: 21.9571\n",
            "Epoch [91/100], Loss: 21.9730\n",
            "Epoch [92/100], Loss: 21.9838\n",
            "Epoch [93/100], Loss: 21.9605\n",
            "Epoch [94/100], Loss: 21.9401\n",
            "Epoch [95/100], Loss: 21.9564\n",
            "Epoch [96/100], Loss: 21.9873\n",
            "Epoch [97/100], Loss: 22.0109\n",
            "Epoch [98/100], Loss: 21.9542\n",
            "Epoch [99/100], Loss: 22.0014\n",
            "Epoch [100/100], Loss: 21.9313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/sample_data/Vectorized_Seoul_Datas2020.csv')\n",
        "\n",
        "x = df[['Hour Time', 'Temperature', 'Humidity', 'Weekday', 'Code']].values\n",
        "\n",
        "onehot_code = np.eye(5)[x[:, 4].astype(int)]\n",
        "x = np.hstack((x[:, :4], onehot_code))\n",
        "vectors = df[\"Vector\"].apply(lambda x: [int(i) for i in x.split(\",\")]).tolist()\n",
        "\n",
        "datas = torch.from_numpy(x).float()\n",
        "labels = torch.tensor(vectors).float()"
      ],
      "metadata": {
        "id": "C1u46IP8DHkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(datas, labels)\n",
        "train_dataset = dataset\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "fX5q_f5hDQeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epoch = 100\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "  epoch_loss = 0.0\n",
        "  for inputs, labels in train_dataloader:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    \n",
        "    loss = criterion(outputs, labels)\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epoch, epoch_loss / len(train_dataloader)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d9be97a-e933-4904-f096-02a69a298f78",
        "id": "bJpSzBzBDa3p"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 20.6171\n",
            "Epoch [2/100], Loss: 20.1774\n",
            "Epoch [3/100], Loss: 20.1075\n",
            "Epoch [4/100], Loss: 20.0062\n",
            "Epoch [5/100], Loss: 20.0171\n",
            "Epoch [6/100], Loss: 19.9327\n",
            "Epoch [7/100], Loss: 19.9087\n",
            "Epoch [8/100], Loss: 19.9549\n",
            "Epoch [9/100], Loss: 19.8846\n",
            "Epoch [10/100], Loss: 19.9293\n",
            "Epoch [11/100], Loss: 19.8778\n",
            "Epoch [12/100], Loss: 19.9174\n",
            "Epoch [13/100], Loss: 19.8767\n",
            "Epoch [14/100], Loss: 19.8815\n",
            "Epoch [15/100], Loss: 19.7863\n",
            "Epoch [16/100], Loss: 19.9584\n",
            "Epoch [17/100], Loss: 19.7944\n",
            "Epoch [18/100], Loss: 19.7153\n",
            "Epoch [19/100], Loss: 19.8579\n",
            "Epoch [20/100], Loss: 19.7294\n",
            "Epoch [21/100], Loss: 19.7588\n",
            "Epoch [22/100], Loss: 19.6207\n",
            "Epoch [23/100], Loss: 19.6218\n",
            "Epoch [24/100], Loss: 19.6212\n",
            "Epoch [25/100], Loss: 19.6958\n",
            "Epoch [26/100], Loss: 19.6370\n",
            "Epoch [27/100], Loss: 19.6547\n",
            "Epoch [28/100], Loss: 19.5635\n",
            "Epoch [29/100], Loss: 19.5559\n",
            "Epoch [30/100], Loss: 19.5218\n",
            "Epoch [31/100], Loss: 19.4783\n",
            "Epoch [32/100], Loss: 19.5086\n",
            "Epoch [33/100], Loss: 19.5466\n",
            "Epoch [34/100], Loss: 19.4867\n",
            "Epoch [35/100], Loss: 19.4326\n",
            "Epoch [36/100], Loss: 19.4195\n",
            "Epoch [37/100], Loss: 19.4329\n",
            "Epoch [38/100], Loss: 19.4592\n",
            "Epoch [39/100], Loss: 19.3881\n",
            "Epoch [40/100], Loss: 19.3700\n",
            "Epoch [41/100], Loss: 19.3705\n",
            "Epoch [42/100], Loss: 19.2992\n",
            "Epoch [43/100], Loss: 19.3214\n",
            "Epoch [44/100], Loss: 19.2095\n",
            "Epoch [45/100], Loss: 19.2554\n",
            "Epoch [46/100], Loss: 19.2473\n",
            "Epoch [47/100], Loss: 19.1992\n",
            "Epoch [48/100], Loss: 19.2136\n",
            "Epoch [49/100], Loss: 19.1280\n",
            "Epoch [50/100], Loss: 19.1890\n",
            "Epoch [51/100], Loss: 19.1488\n",
            "Epoch [52/100], Loss: 19.1501\n",
            "Epoch [53/100], Loss: 19.0582\n",
            "Epoch [54/100], Loss: 19.0358\n",
            "Epoch [55/100], Loss: 19.0769\n",
            "Epoch [56/100], Loss: 19.0568\n",
            "Epoch [57/100], Loss: 19.1035\n",
            "Epoch [58/100], Loss: 19.0379\n",
            "Epoch [59/100], Loss: 19.1032\n",
            "Epoch [60/100], Loss: 18.9725\n",
            "Epoch [61/100], Loss: 19.0461\n",
            "Epoch [62/100], Loss: 18.9555\n",
            "Epoch [63/100], Loss: 18.9565\n",
            "Epoch [64/100], Loss: 18.9951\n",
            "Epoch [65/100], Loss: 18.7967\n",
            "Epoch [66/100], Loss: 18.9552\n",
            "Epoch [67/100], Loss: 18.8496\n",
            "Epoch [68/100], Loss: 18.8809\n",
            "Epoch [69/100], Loss: 19.0346\n",
            "Epoch [70/100], Loss: 18.8620\n",
            "Epoch [71/100], Loss: 18.8195\n",
            "Epoch [72/100], Loss: 18.9221\n",
            "Epoch [73/100], Loss: 18.7598\n",
            "Epoch [74/100], Loss: 18.7930\n",
            "Epoch [75/100], Loss: 18.7277\n",
            "Epoch [76/100], Loss: 18.7336\n",
            "Epoch [77/100], Loss: 18.7524\n",
            "Epoch [78/100], Loss: 18.8346\n",
            "Epoch [79/100], Loss: 18.7632\n",
            "Epoch [80/100], Loss: 18.7752\n",
            "Epoch [81/100], Loss: 18.7368\n",
            "Epoch [82/100], Loss: 18.6889\n",
            "Epoch [83/100], Loss: 18.7030\n",
            "Epoch [84/100], Loss: 18.7243\n",
            "Epoch [85/100], Loss: 18.6654\n",
            "Epoch [86/100], Loss: 18.6803\n",
            "Epoch [87/100], Loss: 18.6662\n",
            "Epoch [88/100], Loss: 18.6726\n",
            "Epoch [89/100], Loss: 18.6048\n",
            "Epoch [90/100], Loss: 18.6569\n",
            "Epoch [91/100], Loss: 18.6687\n",
            "Epoch [92/100], Loss: 18.6423\n",
            "Epoch [93/100], Loss: 18.6148\n",
            "Epoch [94/100], Loss: 18.6028\n",
            "Epoch [95/100], Loss: 18.5816\n",
            "Epoch [96/100], Loss: 18.5449\n",
            "Epoch [97/100], Loss: 18.5934\n",
            "Epoch [98/100], Loss: 18.4644\n",
            "Epoch [99/100], Loss: 18.6044\n",
            "Epoch [100/100], Loss: 18.4398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/sample_data/Vectorized_Seoul_Datas2021.csv')\n",
        "\n",
        "x = df[['Hour Time', 'Temperature', 'Humidity', 'Weekday', 'Code']].values\n",
        "\n",
        "onehot_code = np.eye(5)[x[:, 4].astype(int)]\n",
        "x = np.hstack((x[:, :4], onehot_code))\n",
        "vectors = df[\"Vector\"].apply(lambda x: [int(i) for i in x.split(\",\")]).tolist()\n",
        "\n",
        "datas = torch.from_numpy(x).float()\n",
        "labels = torch.tensor(vectors).float()"
      ],
      "metadata": {
        "id": "oYTkbjMjD5pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(datas, labels)\n",
        "train_dataset = dataset\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "qPWf_ex8D5pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epoch = 100\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "  epoch_loss = 0.0\n",
        "  for inputs, labels in train_dataloader:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    \n",
        "    loss = criterion(outputs, labels)\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epoch, epoch_loss / len(train_dataloader)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01e41043-6dd0-4fd6-bcf3-cb2b4b76cd89",
        "id": "lMbOLhT2D5pk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 20.7059\n",
            "Epoch [2/100], Loss: 19.1266\n",
            "Epoch [3/100], Loss: 18.7282\n",
            "Epoch [4/100], Loss: 18.6543\n",
            "Epoch [5/100], Loss: 18.2148\n",
            "Epoch [6/100], Loss: 18.2969\n",
            "Epoch [7/100], Loss: 18.3614\n",
            "Epoch [8/100], Loss: 18.0163\n",
            "Epoch [9/100], Loss: 18.6333\n",
            "Epoch [10/100], Loss: 17.8062\n",
            "Epoch [11/100], Loss: 18.1392\n",
            "Epoch [12/100], Loss: 17.9521\n",
            "Epoch [13/100], Loss: 18.4555\n",
            "Epoch [14/100], Loss: 17.9246\n",
            "Epoch [15/100], Loss: 18.3677\n",
            "Epoch [16/100], Loss: 18.0653\n",
            "Epoch [17/100], Loss: 17.7986\n",
            "Epoch [18/100], Loss: 17.9004\n",
            "Epoch [19/100], Loss: 17.7883\n",
            "Epoch [20/100], Loss: 17.9556\n",
            "Epoch [21/100], Loss: 17.7778\n",
            "Epoch [22/100], Loss: 17.5993\n",
            "Epoch [23/100], Loss: 17.9295\n",
            "Epoch [24/100], Loss: 17.5554\n",
            "Epoch [25/100], Loss: 18.0196\n",
            "Epoch [26/100], Loss: 17.8721\n",
            "Epoch [27/100], Loss: 17.8468\n",
            "Epoch [28/100], Loss: 18.0897\n",
            "Epoch [29/100], Loss: 17.6927\n",
            "Epoch [30/100], Loss: 17.5174\n",
            "Epoch [31/100], Loss: 17.7927\n",
            "Epoch [32/100], Loss: 17.7555\n",
            "Epoch [33/100], Loss: 17.4532\n",
            "Epoch [34/100], Loss: 17.3344\n",
            "Epoch [35/100], Loss: 17.3892\n",
            "Epoch [36/100], Loss: 17.2753\n",
            "Epoch [37/100], Loss: 17.5373\n",
            "Epoch [38/100], Loss: 17.1362\n",
            "Epoch [39/100], Loss: 17.1864\n",
            "Epoch [40/100], Loss: 17.4418\n",
            "Epoch [41/100], Loss: 17.3749\n",
            "Epoch [42/100], Loss: 17.2961\n",
            "Epoch [43/100], Loss: 17.3825\n",
            "Epoch [44/100], Loss: 17.3402\n",
            "Epoch [45/100], Loss: 17.6334\n",
            "Epoch [46/100], Loss: 17.2553\n",
            "Epoch [47/100], Loss: 17.3724\n",
            "Epoch [48/100], Loss: 17.4431\n",
            "Epoch [49/100], Loss: 17.2224\n",
            "Epoch [50/100], Loss: 17.3577\n",
            "Epoch [51/100], Loss: 17.2937\n",
            "Epoch [52/100], Loss: 16.9414\n",
            "Epoch [53/100], Loss: 17.3660\n",
            "Epoch [54/100], Loss: 17.2903\n",
            "Epoch [55/100], Loss: 17.1874\n",
            "Epoch [56/100], Loss: 17.2058\n",
            "Epoch [57/100], Loss: 17.0407\n",
            "Epoch [58/100], Loss: 17.2408\n",
            "Epoch [59/100], Loss: 17.4309\n",
            "Epoch [60/100], Loss: 17.1295\n",
            "Epoch [61/100], Loss: 17.2398\n",
            "Epoch [62/100], Loss: 17.1410\n",
            "Epoch [63/100], Loss: 17.0888\n",
            "Epoch [64/100], Loss: 17.1019\n",
            "Epoch [65/100], Loss: 17.1253\n",
            "Epoch [66/100], Loss: 17.1029\n",
            "Epoch [67/100], Loss: 17.1372\n",
            "Epoch [68/100], Loss: 16.9097\n",
            "Epoch [69/100], Loss: 16.7474\n",
            "Epoch [70/100], Loss: 16.9796\n",
            "Epoch [71/100], Loss: 17.2834\n",
            "Epoch [72/100], Loss: 16.8504\n",
            "Epoch [73/100], Loss: 16.7349\n",
            "Epoch [74/100], Loss: 17.0981\n",
            "Epoch [75/100], Loss: 17.0030\n",
            "Epoch [76/100], Loss: 16.9885\n",
            "Epoch [77/100], Loss: 17.0071\n",
            "Epoch [78/100], Loss: 17.1464\n",
            "Epoch [79/100], Loss: 16.9897\n",
            "Epoch [80/100], Loss: 16.8802\n",
            "Epoch [81/100], Loss: 17.1350\n",
            "Epoch [82/100], Loss: 17.2366\n",
            "Epoch [83/100], Loss: 17.0709\n",
            "Epoch [84/100], Loss: 16.9936\n",
            "Epoch [85/100], Loss: 16.8574\n",
            "Epoch [86/100], Loss: 16.8000\n",
            "Epoch [87/100], Loss: 16.8626\n",
            "Epoch [88/100], Loss: 17.0265\n",
            "Epoch [89/100], Loss: 16.7857\n",
            "Epoch [90/100], Loss: 16.6931\n",
            "Epoch [91/100], Loss: 16.8369\n",
            "Epoch [92/100], Loss: 16.8202\n",
            "Epoch [93/100], Loss: 16.9682\n",
            "Epoch [94/100], Loss: 16.7443\n",
            "Epoch [95/100], Loss: 17.1253\n",
            "Epoch [96/100], Loss: 16.7023\n",
            "Epoch [97/100], Loss: 16.5672\n",
            "Epoch [98/100], Loss: 17.0232\n",
            "Epoch [99/100], Loss: 16.6530\n",
            "Epoch [100/100], Loss: 16.6023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'my_model.pth')"
      ],
      "metadata": {
        "id": "z_7PAOO2FEh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ig-V928KIyLM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}